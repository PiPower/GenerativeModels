@misc{how_to_train,
      title={How to Train Deep Variational Autoencoders and Probabilistic Ladder Networks}, 
      author={Sønderby, Casper Kaae; Raiko, Tapani; Maaløe, Lars; Sønderby, Søren Kaae; Winther, Ole},
      year={2016},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{wprowadzenie,
   title={An Introduction to Variational Autoencoders},
   volume={12},
   ISSN={1935-8245},
   url={http://dx.doi.org/10.1561/2200000056},
   DOI={10.1561/2200000056},
   number={4},
   journal={Foundations and Trends® in Machine Learning},
   publisher={Now Publishers},
   author={Kingma, Diederik P. and Welling, Max},
   year={2019},
   pages={307–392} }

@misc{bigGAN,
      title={Large Scale GAN Training for High Fidelity Natural Image Synthesis}, 
      author={Andrew Brock and Jeff Donahue and Karen Simonyan},
      year={2019},
      eprint={1809.11096},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1809.11096} 
}

@misc{var_bayes,
      title={Auto-Encoding Variational Bayes}, 
      author={Diederik P Kingma and Max Welling},
      year={2022},
      eprint={1312.6114},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{nvidia_gtc,
      title={GTC March 2024 Keynote with NVIDIA CEO Jensen Huang}, 
      author={Jensen Huang},
      year={2024},
      howpublished= "\url{https://www.youtube.com/watch?v=Y2F8yisiS6E&list=PLZHnYvH1qtOYPPHRaHf9yPQkIcGpIUpdL&index=1}",
}

@misc{Ladder_models,
      title={Ladder Variational Autoencoders}, 
      author={Casper Kaae Sønderby and Tapani Raiko and Lars Maaløe and Søren Kaae Sønderby and Ole Winther},
      year={2016},
      eprint={1602.02282},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{elbo_grad,
      title={Estimating the gradient of the ELBO}, 
      author={Massimiliano Patacchiola},
      year={2021}
}

@misc{Structured_model,
      title={A Structured Variational Auto-encoder for Learning Deep Hierarchies of Sparse Features}, 
      author={Tim Salimans},
      year={2016},
      eprint={1602.08734},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}
-----------------6---------------------

@misc{VQ-VAE,
      title={Neural Discrete Representation Learning}, 
      author={Aaron van den Oord and Oriol Vinyals and Koray Kavukcuoglu},
      year={2018},
      eprint={1711.00937},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{celeba_hq,
      title={Progressive Growing of GANs for Improved Quality, Stability, and Variation}, 
      author={Tero Karras and Timo Aila and Samuli Laine and Jaakko Lehtinen},
      year={2018},
      eprint={1710.10196},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}

@misc{p_gan,
      title={Deep Unsupervised Learning using Nonequilibrium Thermodynamics}, 
      author={Jascha Sohl-Dickstein and Eric A. Weiss and Niru Maheswaranathan and Surya Ganguli},
      year={2015},
      eprint={1503.03585},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{ddm,
      title={Denoising Diffusion Probabilistic Models}, 
      author={Jonathan Ho and Ajay Jain and Pieter Abbeel},
      year={2020},
      eprint={2006.11239},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{additional_explanation,
      title={Understanding Diffusion Models: A Unified Perspective}, 
      author={Calvin Luo},
      year={2022},
      eprint={2208.11970},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{dalle_1,
      title={Zero-Shot Text-to-Image Generation}, 
      author={Aditya Ramesh and Mikhail Pavlov and Gabriel Goh and Scott Gray and Chelsea Voss and Alec Radford and Mark Chen and Ilya Sutskever},
      year={2021},
      eprint={2102.12092},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

---------------------------- 12 -----------------------

@misc{Conflict,
      title={Israel under pressure to justify its use of AI in Gaza}, 
      author={JOSEPH GEDEON and MAGGIE MILLER},
      year={2024},   
      howpublished  = "\url{https://www.politico.com/news/2024/03/03/israel-ai-warfare-gaza-00144491}"
}

@misc{ranking,
      title={Architektury generujące obrazy o najwyższej jakości}, 
      howpublished  = "\url{https://paperswithcode.com/task/image-generation}",
      year = {2024}
}

@misc{VQ_VAE2,
      title={Generating Diverse High-Fidelity Images with VQ-VAE-2}, 
      author={Ali Razavi and Aaron van den Oord and Oriol Vinyals},
      year={2019},
      eprint={1906.00446},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{NVAE,
      title={NVAE: A Deep Hierarchical Variational Autoencoder}, 
      author={Arash Vahdat and Jan Kautz},
      year={2021},
      eprint={2007.03898},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{improved_ddm,
      title={Improved Denoising Diffusion Probabilistic Models}, 
      author={Alex Nichol and Prafulla Dhariwal},
      year={2021},
      eprint={2102.09672},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{score_model,
      title={Generative Modeling by Estimating Gradients of the Data Distribution}, 
      author={Yang Song and Stefano Ermon},
      year={2020},
      eprint={1907.05600},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{score_model_blog,
      title={Generative Modeling by Estimating Gradients of the Data Distribution (blog)}, 
      author={Yang Song},
      year = {2021}
}
-------------- 18 -------------------------
@misc{what_dif_mod,
      title   = "What are diffusion models?",
      author  = "Weng, Lilian",
      journal = "lilianweng.github.io",
      year    = "2021",
      month   = "Jul",
      url     = "https://lilianweng.github.io/posts/2021-07-11-diffusion-models/"
}


@misc{score_model_begin,
      title={Estimation of Non-Normalized Statistical Models by Score Matching}, 
      author={Aapo Hyv¨arinen},
      year={2005}
}

@misc{refine_net,
      title={RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation}, 
      author={Guosheng Lin and Anton Milan and Chunhua Shen and Ian Reid},
      year={2016},
      eprint={1611.06612},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{denoising_score,
      title={A Connection Between Score Matching and Denoising Autoencoders}, 
      author={Pascal Vincent},
      year={2010}
}
@misc{improved_score,
      title={Improved Techniques for Training Score-Based Generative Models}, 
      author={Yang Song and Stefano Ermon},
      year={2020},
      eprint={2006.09011},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{score_sde,
      title={Score-Based Generative Modeling through Stochastic Differential Equations}, 
      author={Yang Song and Jascha Sohl-Dickstein and Diederik P. Kingma and Abhishek Kumar and Stefano Ermon and Ben Poole},
      year={2021},
      eprint={2011.13456},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{reverse_time_SDE,
title = {Reverse-time diffusion equation models},
journal = {Stochastic Processes and their Applications},
volume = {12},
number = {3},
pages = {313-326},
year = {1982},
issn = {0304-4149},
doi = {https://doi.org/10.1016/0304-4149(82)90051-5},
url = {https://www.sciencedirect.com/science/article/pii/0304414982900515},
author = {Brian D.O. Anderson},
abstract = {Reverse-time stochastic diffusion equation models are defined and it is shown how most processes defined via a forward-time or conventional diffusion equation model have an associated reverse-time model.}
}
@inproceedings{alexnet,
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
title = {ImageNet classification with deep convolutional neural networks},
year = {2012},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overriding in the fully-connected layers we employed a recently-developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.},
booktitle = {Proceedings of the 25th International Conference on Neural Information Processing Systems - Volume 1},
pages = {1097–1105},
numpages = {9},
location = {Lake Tahoe, Nevada},
series = {NIPS'12}
}


@misc{gpu_guide,
      title={NVIDIA CUDA Programming Guide}, 
      howpublished  = "\url{https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html}",
      year = {2024}
}

@misc{gpt_popularity,
      author = { Fabio Duarte},
      title = {Number of ChatGPT Users (Jul 2024)},
      howpublished  = "\url{https://explodingtopics.com/blog/chatgpt-users}",
      year = {2024}
}

@misc{ai_copyright,
      author = { James Vincent},
       title = {The lawsuit that could rewrite the rules of AI copyright},
      howpublished  = "\url{https://www.theverge.com/2022/11/8/23446821/}",
      year = {2022}
}

@misc{ai_replika,
      title = {Replika},
      howpublished  = "\url{https://replika.com/}",
      year = {2024}
}


@misc{claudia_ai,
      author = { Ej Dickson},
      title = {They’re Selling Nudes of Imaginary Women on Reddit — and It’s Working},
      howpublished  = "\url{https://www.rollingstone.com/culture/culture-features/ai-nudes-selling-reddit-1234708474/}",
     year = {2023}
}
@misc{ai_picso,
      title={PicSo},
      howpublished  = "\url{https://www.picso.ai/}",
      year = {2024}
}   

@misc{ai_false_texts,
      author = {Ben Nimmo},
        year = {2024},
      title={AI and Covert Influence Operations: Latest Trends},
      howpublished  = "\url{https://downloads.ctfassets.net/kftzwdyauwt9/5IMxzTmUclSOAcWUXbkVrK/3cfab518e6b10789ab8843bcca18b633/Threat_Intel_Report.pdf}"
}

@misc{transformery,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{gan_base,
      title={Generative Adversarial Networks}, 
      author={Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
      year={2014},
      eprint={1406.2661},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{llama_hug_face,
      title = {Llama Hugging Face},
            author={Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Dan Bikel and Lukas Blecher and Cristian Canton Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel Kloumann and Artem Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and Ranjan Subramanian and Xiaoqing Ellen Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zheng Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
      year={2023},
      howpublished  = "\url{https://huggingface.co/docs/transformers/model_doc/llama2}"
}
@misc{resnet_block,
      title={Deep Residual Learning for Image Recognition}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2015},
      eprint={1512.03385},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{gpt_3,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{emergent,
      title={The Unpredictable Abilities Emerging From Large AI Models}, 
      author={Stephen Ornes},
    howpublished  = "\url{https://www.quantamagazine.org/the-unpredictable-abilities-emerging-from-large-ai-models-20230316/}",
      year = {2023}
}
@misc{SDXL,
      title={SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis}, 
      author={Dustin Podell and Zion English and Kyle Lacey and Andreas Blattmann and Tim Dockhorn and Jonas Müller and Joe Penna and Robin Rombach},
      year={2023},
      eprint={2307.01952},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{lion_dataset,
      title={LAION-5B: An open large-scale dataset for training next generation image-text models}, 
      author={Christoph Schuhmann and Romain Beaumont and Richard Vencu and Cade Gordon and Ross Wightman and Mehdi Cherti and Theo Coombes and Aarush Katta and Clayton Mullis and Mitchell Wortsman and Patrick Schramowski and Srivatsa Kundurthy and Katherine Crowson and Ludwig Schmidt and Robert Kaczmarczyk and Jenia Jitsev},
      year={2022},
      eprint={2210.08402},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2210.08402}, 
}
@misc{ret_net,
      title={Retentive Network: A Successor to Transformer for Large Language Models}, 
      author={Yutao Sun and Li Dong and Shaohan Huang and Shuming Ma and Yuqing Xia and Jilong Xue and Jianyong Wang and Furu Wei},
      year={2023},
      eprint={2307.08621},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{liquid_net,
      title={Liquid Time-constant Networks}, 
      author={Ramin Hasani and Mathias Lechner and Alexander Amini and Daniela Rus and Radu Grosu},
      year={2020},
      eprint={2006.04439},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{stable_diff,
      title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
      year={2022},
      eprint={2112.10752},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{dalle_3,
  title={Improving Image Generation with Better Captions},
  author={James Betker and Gabriel Goh and Li Jing and TimBrooks and Jianfeng Wang and Linjie Li and Long Ouyang and Juntang Zhuang and Joyce Lee and Yufei Guo and Wesam Manassra and Prafulla Dhariwal and Casey Chu and Yunxin Jiao and Aditya Ramesh},
}
@book{Särkkä_Solin_2019, place={Cambridge}, series={Institute of Mathematical Statistics Textbooks}, title={Applied Stochastic Differential Equations}, publisher={Cambridge University Press}, author={Särkkä, Simo and Solin, Arno}, year={2019}, collection={Institute of Mathematical Statistics Textbooks}}